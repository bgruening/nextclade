#!/usr/bin/env bash
set -euo pipefail
trap "exit" INT
THIS_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Runs smoke tests - basic use-case checks with default data
# https://en.wikipedia.org/wiki/Smoke_testing_(software)
#
# Dependencies:
#   sudo apt-get install -y bash curl parallel
#
#   curl -fsSL "https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64" -o "${HOME}/bin/jq" && chmod +x "${HOME}/bin/jq"
#
#   curl -sSL "https://github.com/shenwei356/seqkit/releases/download/v2.5.0/seqkit_linux_amd64.tar.gz" | tar -C "${HOME}/bin" -xz "seqkit"
#
# Usage (NOTE: you must build and re-build Nextclade executable yourself, this script does not do that):
#
# 1. Download datasets from the default dataset server and run tests with a given nextclade executable:
#
#     ./tests/run-smoke-tests 'target/release/nextclade'
#
# The downloaded datasets will be in "${DATASETS_DIR}" and Nextclade output files will be in "${RESULTS_DIR}" (see below)
#
#
# 2. Run tests with a given nextclade executable and a directory containing datasets. Dataset directories are
#    identified as directories containing a 'pathogen.json' file.
#
#     ./tests/run-smoke-tests 'target/release/nextclade' '.../nextclade_data/data_output'

export NEXTCLADE_BIN="${1:? "Usage: ${0} <path_to_nextclade> [path_to_dataset_collection_dir]"}"
export INPUT_DATASETS_DIR="${2:-}"

export DATASETS_DIR="${THIS_DIR}/../tmp/smoke-tests/dataset"
export RESULTS_DIR="${THIS_DIR}/../tmp/smoke-tests/result"

function run_with_name() {
  local name="${1}"
  local sequences="${2}"
  local out_dir="${RESULTS_DIR}/${name}/with_name"

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --dataset-name="${name}" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_name

function run_with_dataset_dir() {
  local name="${1}"
  local dataset_dir="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_dataset"

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-dataset="${dataset_dir}" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_dataset_dir

function run_with_dataset_zip() {
  local name="${1}"
  local zip_path="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_dataset_zip"

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-dataset="${zip_path}" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_dataset_zip

function run_with_ref_only() {
  local name="${1}"
  local dataset_dir="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_ref_only"

  if [ ! -f "${dataset_dir}/reference.fasta" ]; then return; fi

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-ref="${dataset_dir}/reference.fasta" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_ref_only

function run_with_ref_and_annotation() {
  local name="${1}"
  local dataset_dir="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_ref_and_annotation"

  if [ ! -f "${dataset_dir}/reference.fasta" ]; then return; fi
  if [ ! -f "${dataset_dir}/genome_annotation.gff3" ]; then return; fi

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-ref="${dataset_dir}/reference.fasta" \
    --input-annotation="${dataset_dir}/genome_annotation.gff3" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_ref_and_annotation

function run_with_ref_and_tree() {
  local name="${1}"
  local dataset_dir="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_ref_and_tree"

  if [ ! -f "${dataset_dir}/reference.fasta" ]; then return; fi
  if [ ! -f "${dataset_dir}/tree.json" ]; then return; fi

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-ref="${dataset_dir}/reference.fasta" \
    --input-tree="${dataset_dir}/tree.json" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_ref_and_tree

function run_with_ref_and_annotation_and_tree() {
  local name="${1}"
  local dataset_dir="${2}"
  local sequences="${3}"
  local out_dir="${RESULTS_DIR}/${name}/with_ref_and_annotation_and_tree"

  if [ ! -f "${dataset_dir}/genome_annotation.gff3" ]; then return; fi
  if [ ! -f "${dataset_dir}/tree.json" ]; then return; fi

  "${NEXTCLADE_BIN}" run --quiet --retry-reverse-complement --in-order --include-reference \
    --input-ref="${dataset_dir}/reference.fasta" \
    --input-annotation="${dataset_dir}/genome_annotation.gff3" \
    --input-tree="${dataset_dir}/tree.json" \
    --output-translations="${out_dir}/translations/{cds}.translation.fasta" \
    --output-all="${out_dir}" \
    "${sequences}"
}
export -f run_with_ref_and_annotation_and_tree

function get_sequence_file() {
  local dataset_dir="${1}"
  local target_dir="${2}"

  local sequences
  sequences="$(jq -re ".files.examples | select(length > 0)" "${dataset_dir}/pathogen.json" 2>/dev/null || printf "")"
  local msg_no_sequences=""
  if [ -n "${sequences}" ] && [ -f "${dataset_dir}/${sequences}" ]; then
    if [ "${target_dir}" != "${dataset_dir}" ]; then
      cp "${dataset_dir}/${sequences}" "${target_dir}/"
    fi
    sequences="${target_dir}/${sequences}"
  else
    if [ "${target_dir}" != "${dataset_dir}" ]; then
      cp "${dataset_dir}/reference.fasta" "${target_dir}/"
    fi
    sequences="${target_dir}/reference.fasta"
    msg_no_sequences="1"
  fi

  printf "%s|%s" "${sequences}" "${msg_no_sequences}"
}
export -f get_sequence_file

function add_reverse_complement() {
  local sequences="${1}"

  if command -v seqkit &>/dev/null; then
    local sequences_orig="${sequences%.fasta}.orig.fasta"
    local sequences_rev_comp="${sequences%.fasta}.rev.fasta"
    cp "${sequences}" "${sequences_orig}"
    seqkit seq --quiet -t DNA -p -r "${sequences_orig}" | seqkit replace -p '(.*)' -r 'SMOKE_TEST_REVERSE_COMPLEMENTED_SEQUENCE|$1' >"${sequences_rev_comp}"
    (
      cat "${sequences_orig}"
      printf "\n"
      cat "${sequences_rev_comp}"
    ) >"${sequences}"
  fi
}
export -f add_reverse_complement

function download_and_run_dataset() {
  local name="${1}"
  local dataset_dir="${DATASETS_DIR}/dir/${name}"
  local zip_path="${DATASETS_DIR}/zip/${name}/dataset.zip"

  "${NEXTCLADE_BIN}" dataset get --name="${name}" --output-dir="${dataset_dir}"
  "${NEXTCLADE_BIN}" dataset get --name="${name}" --output-zip="${zip_path}"

  local result
  result=$(get_sequence_file "${dataset_dir}" "${dataset_dir}")
  local sequences="${result%|*}"
  local has_warning="${result#*|}"

  add_reverse_complement "${sequences}"

  if [ "${has_warning}" = "1" ]; then
    printf "\nRunning '%s' for '%s'\n\e[93mWarning: dataset '%s' contains no example sequences. Will use reference sequence as query input.\e[0m\n" "${NEXTCLADE_BIN}" "${name}" "${name}"
  else
    printf "\nRunning '%s' for '%s'\n" "${NEXTCLADE_BIN}" "${name}"
  fi

  # Run with dataset name (only for downloaded datasets)
  run_with_name "${name}" "${sequences}"

  # Run directory-based tests
  run_with_dataset_dir "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_only "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_annotation "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_tree "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_annotation_and_tree "${name}" "${dataset_dir}" "${sequences}"

  # If dataset.zip exists, also run zip-based test
  if [ -f "${dataset_dir}/dataset.zip" ]; then
    run_with_dataset_zip "${name}" "${dataset_dir}/dataset.zip" "${sequences}"
  fi
}
export -f download_and_run_dataset

function run_local_dataset() {
  local dataset_dir="${1}"

  # Extract dataset name as path relative to INPUT_DATASETS_DIR
  local abs_input_dir
  abs_input_dir="$(cd "${INPUT_DATASETS_DIR}" && pwd)"
  local abs_dataset_dir
  abs_dataset_dir="$(cd "${dataset_dir}" && pwd)"
  local name
  name="$(printf "%s" "${abs_dataset_dir}" | sed "s|^${abs_input_dir}/||")"

  # Create organized directory for this dataset's sequences
  local work_dataset_dir="${DATASETS_DIR}/local/${name}"
  mkdir -p "${work_dataset_dir}"

  local result
  result=$(get_sequence_file "${dataset_dir}" "${work_dataset_dir}")
  local sequences="${result%|*}"
  local has_warning="${result#*|}"

  add_reverse_complement "${sequences}"

  if [ "${has_warning}" = "1" ]; then
    printf "\nRunning '%s' for '%s'\n\e[93mWarning: dataset '%s' contains no example sequences. Will use reference sequence as query input.\e[0m\n" "${NEXTCLADE_BIN}" "${name}" "${name}"
  else
    printf "\nRunning '%s' for '%s'\n" "${NEXTCLADE_BIN}" "${name}"
  fi

  # Run directory-based tests
  run_with_dataset_dir "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_only "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_annotation "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_tree "${name}" "${dataset_dir}" "${sequences}"
  run_with_ref_and_annotation_and_tree "${name}" "${dataset_dir}" "${sequences}"

  # If dataset.zip exists, also run zip-based test
  if [ -f "${dataset_dir}/dataset.zip" ]; then
    run_with_dataset_zip "${name}" "${dataset_dir}/dataset.zip" "${sequences}"
  fi
}
export -f run_local_dataset

if [ -n "${INPUT_DATASETS_DIR}" ]; then
  printf "Running smoke tests with datasets from: %s\n" "${INPUT_DATASETS_DIR}"

  if [ ! -d "${INPUT_DATASETS_DIR}" ]; then
    printf "Error: Dataset directory '%s' does not exist\n" "${INPUT_DATASETS_DIR}"
    exit 1
  fi

  # Find all directories containing pathogen.json files
  mapfile -t -d '' dataset_dirs < <(find "${INPUT_DATASETS_DIR}" -name "pathogen.json" -type f -printf '%h\0' | sort -zu)

  if ((${#dataset_dirs[@]} == 0)); then
    printf "Error: No datasets found (directories containing pathogen.json files) in '%s'\n" "${INPUT_DATASETS_DIR}"
    exit 1
  fi

  printf "Found %d datasets\n" "${#dataset_dirs[@]}"

  parallel --jobs=+0 run_local_dataset ::: "${dataset_dirs[@]}"
else
  printf "Downloading datasets and running smoke tests\n"
  all_datasets="$("${NEXTCLADE_BIN}" dataset list --include-deprecated --only-names)"
  printf "Will download %d datasets\n" "$(printf "%s" "${all_datasets}" | wc -l)"
  parallel --jobs=+0 download_and_run_dataset ::: "${all_datasets}"
fi
